from count_schools import SchoolData, Constants
import csv
import time


class SchoolDataSearch(SchoolData):
    def __init__(self, data_file: str, state_mapping_file: str):
        super().__init__(data_file)
        self.state_name = {}
        self.reverse_index = {}
        # the default encoding of utf-8 throws exceptions, this one however works.
        # another approach would be to catch and log the lines that throw exceptions
        # The state mapping file is needed since the states provided in the data are
        # abbreviated into 2 letters (or 1 in a certain case) but the queries are done
        # for the full state name
        with open(state_mapping_file, 'r', encoding="latin-1") as csv_file:
            csv_reader = csv.reader(csv_file, delimiter=',', skipinitialspace=True)
            for row in csv_reader:
                self.state_name[row[1]] = row[0]

    def generate_reverse_index(self):
        """
        Generate an Elastic-Search style reverse index of words from input data.
        This is inverted as compared to traditional indexes that index on the
        basis of entire records. The tokens are generated by word-basis, split on
        space separators.
        """
        for index, school in enumerate(self.schools):
            try:
                string = school[Constants.NAME_INDEX] + school[Constants.CITY_INDEX] + \
                         self.state_name[school[Constants.STATE_INDEX]]
                tokens = string.split()
                for token in tokens:
                    # skip all tokens that are not alphanumeric (e.g. "-")
                    if token.isalpha():
                        if token in self.reverse_index:
                            self.reverse_index[token].append(index)
                        else:
                            self.reverse_index[token] = [index]
            except Exception as e:
                print(e)

    def _search_schools(self, query: str, total_matches_needed: int = 3):
        """
        Split search query into tokens separated by spaces then query each word
        in the reverse index for which rows (in the school_data.csv) they point to.
        Get the best matches by the number of times the rows (in the school_data)
        occur in the reverse index hits.
        """
        tokens = query.split(" ")
        hit_indexes_counter = {}
        for token_raw in tokens:
            token = token_raw.upper()
            if token in self.reverse_index:
                current_reverse_index = self.reverse_index[token]
                for school in current_reverse_index:
                    if school in hit_indexes_counter:
                        hit_indexes_counter[school] += 1
                    else:
                        hit_indexes_counter[school] = 1
        best_matches = []
        while total_matches_needed > 0 and len(hit_indexes_counter) > 0:
            best_match = max(hit_indexes_counter, key=hit_indexes_counter.get)
            best_matches.append(best_match)
            del hit_indexes_counter[best_match]
            total_matches_needed -= 1
        results = []
        for best_match in best_matches:
            school = self.schools[best_match]
            results.append([school[Constants.NAME_INDEX], school[Constants.CITY_INDEX], school[Constants.STATE_INDEX]])
        return results

    def search_schools(self, query: str, total_matches_needed: int = 3):
        start_time = time.time()
        results = self._search_schools(query, total_matches_needed)
        time_taken = time.time() - start_time
        print("Results for \"%s\" (search took: %.3fs)" % (query, time_taken))
        for index, result in enumerate(results):
            print("%d. %s\n%s, %s" % (index+1, result[0], result[1], result[2]))
